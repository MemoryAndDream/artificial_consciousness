现在有个问题就是模型如何转为实际有意义的东西，否则太久了就会找不到抽象方向

目前看到的一个应用场景：理解人的记忆过程。帮助人学东西。教育学应用。

训练算数

使用chatgpt辅助编程，未来训练ai的可能也是ai，人都快教不了，甚至是引导不了ai了，人可能束缚了ai的思考能力

可以使用chatgpt的会自己产生问题的


可以通过程序模拟各种记忆方案的可靠性，需要的记忆空间，回忆效率

比如理解式记忆比死记硬背的可靠性就高，但是回忆速度慢，需要的记忆空间小？

新目标：
教会加法

语言化数字记忆
11 一十一
分解法 交换律
一位加两位
个位 十位 11-> 一十一 可以视为眼睛的预处理，目前先探索如何通过理解记忆学习两位数加法


不要觉得这样学很慢，事实上，小朋友学加法也不是一小时就能学会的
step1: 个位数字相加 5+6
step2: 多个个位数字相加，中间结果的保存 5+6+3
step3: 十位数字概念

5+6+3 思考过程：
++ 第二个+概念 （未来考虑人主动的想象力作为输入，比如人能想象出2个x，人脑有控制想几遍的功能）
1 看一遍确定是连加
2 连加= 5+6=中间结果11
3 中间结果+3


逻辑拼凑
临时记忆缓存

5+6+7实际上也生成了++的链接，但是要重复了才明显
可以在存储的时候存完整的，然后匹配到部分的时候单独提取出来强化一下
可以预设最后的n个字符都可能被激活
即记忆 abcd   a-0.1  b- 0.5 c -1  d -2 这样，储存的时候还是按长链储存，遗忘一定程度，
或者自然分隔时重置